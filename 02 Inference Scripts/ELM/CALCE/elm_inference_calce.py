# -*- coding: utf-8 -*-
"""ELM Inference CALCE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14Bncz3sFobo83i_cssWN1x3CcSu8DeXs

# Extreme Learning Machine Based Prognostics of Battery Life
**Reference:** R. Razavi-Far, S. Chakrabarti, M. Saif, E. Zio and V. Palade, "Extreme Learning Machine Based Prognostics of Battery Life," in International Journal on Artificial Intelligence Tools, Vol. 27, No. 08 (2018)

DOI: 10.1142/S0218213018500367
"""

# Setting up argument parser
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('-p','--print',action='store_true',
                    help='Print to 16x2 LCD Display')
args = parser.parse_args()


"""## Packages and Functions for Evaluating Performance"""

# For memory tracing
import tracemalloc

def memory_stats(snapshot, key_type='lineno', print_mem=True):
  '''
  Compute memory usage from a tracemalloc snapshot.
  Results are in KiB (Kibibytes).
  '''
  snapshot = snapshot.filter_traces((
      tracemalloc.Filter(False, "<frozen importlib._bootstrap>"),
      tracemalloc.Filter(False, "<unknown>"),
  ))
  usage_stat = snapshot.statistics(key_type)

  total = sum(stat.size for stat in usage_stat)
  total = total / 1024

  if print_mem:
    print(f"Allocated memory: {total:.2f} KiB")

  return total

"""### Start Memory profiling"""

tracemalloc.start()

"""## Start of Inference

### Importing packages
"""

import numpy as np
import random
import math
import os
import torch
import torch.nn as nn
import torch.nn.functional as F

# For timing
from timeit import default_timer as timer

def print_inference_time(start: float,
                     end: float,
                     device: torch.device = None,
                     print_time = True):
  """
  Prints difference between start and end time
  """

  total_time = end - start
  if print_time:
    print(f"Inference time on {device}: {total_time:.3f} seconds")
  
  return total_time

"""### Setting up device-agnostic code"""

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

rul_preds_list = {}

"""### Extreme Learning Machine Architecture"""

class ELM(nn.Module):
  def __init__(self,
               input_size:int,
               hidden_size:int,
               output_size:int,
               activation,
               X_train: torch.tensor,
               y_train: torch.tensor):
    
    super().__init__()

    self.activation = activation

    self.input_weights= torch.normal(mean=0,std=1,size=(input_size, hidden_size), device=X_train.device)
    self.biases = torch.normal(mean=0,std=1,size=(1,hidden_size), device=X_train.device).squeeze(0)

    self.hidden_nodes = self.activation(torch.matmul(X_train, self.input_weights) + self.biases)

    self.output_weights = torch.matmul(torch.linalg.pinv(self.hidden_nodes), y_train)

  def forward(self, x):
    out = self.activation( torch.matmul(x, self.input_weights) + self.biases)
    out = torch.matmul(out, self.output_weights)
    return out

"""### Inference"""

# setup seed
seed = 2
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)

# Battery list
Battery_list = ['CS2_35', 'CS2_36', 'CS2_37', 'CS2_38']

# Parameters
Rated_Capacity = 1.1

window_size = 64
hidden_dim = 1024

# Load model
model = {}
for leave_out in Battery_list:
  model[leave_out] = torch.load(f'checkpoints/ELM_CALCE_{leave_out}.pt', map_location=torch.device(device))

# Load test tensors
X_test, y_test, test_sequence, test_labels = torch.load('test_tensors_ELM_CALCE.pt', map_location=torch.device(device))

"""### One-Step Ahead"""

# End memory snapshot for setup
memsnap_end_setup = tracemalloc.take_snapshot()
print("computing memory usage...")
memuse_end_setup = memory_stats(memsnap_end_setup, print_mem=False)
print("done...")
# End capture memory stats before inference
tracemalloc.stop()

# Define accuracy
def accuracy(y_test: torch.tensor, y_pred: torch.tensor):
  error = torch.abs(y_pred-y_test)/y_test
  acc = 1 - error
  return float(acc)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
from math import sqrt
from datetime import datetime
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

plt.figure(figsize=(40,7))
plt.suptitle('ELM (CALCE) One-Step Ahead',fontsize=15, weight='bold')

OSP_ELM_CALCE = {}

for leave_out, idx in zip(Battery_list, range(len(Battery_list))):
  acc = 0
  pred = []

  # Start timer and tracemalloc
  start_time = timer()
  tracemalloc.start()

  # Do the predictions
  model[leave_out].eval()
  with torch.inference_mode():
    for test_tensor, label in zip(X_test[leave_out], y_test[leave_out]):
      preds = model[leave_out](test_tensor)
      pred.append(preds)
      acc += accuracy(preds, label)

  # End timer and capture memory stats after inference
  end_time = timer()
  memsnap_post_onestep = tracemalloc.take_snapshot()
  tracemalloc.stop()

  # Convert predictions from list to tensor
  pred = torch.cat(pred)

  # Computing memory usage
  memuse_post_onestep = memory_stats(memsnap_post_onestep, print_mem=False)
  memuse_total = memuse_post_onestep + memuse_end_setup

  # Computing metrics
  acc = 100*acc/len(y_test[leave_out])
  mae = mean_absolute_error(y_test[leave_out].cpu(),pred.cpu())
  rmse = mean_squared_error(y_test[leave_out].cpu(),pred.cpu())

  # Computing RUL Error
  Threshold = 0.7 * Rated_Capacity
  idx_true = (y_test[leave_out]<Threshold).nonzero().squeeze() # search idx less than threshold
  RUL_true = idx_true[0][0]                         # first entry is true RUL

  idx_pred = (pred<Threshold).nonzero().squeeze()  # search idx less than threshold
  RUL_pred = idx_pred[0]                        # first entry is pred RUL
  RUL_error = RUL_true - RUL_pred                  # if positive value, earlier than true RUL; 
                                                  # negative value, later than true RUL
  RUL_relative_error = torch.abs(RUL_pred - RUL_true) / RUL_true

  # Printing metrics
  print(f"Extreme Learning Machine (window_size={window_size}, hidden_dim={hidden_dim})\nOne-step ahead Prediction")
  print("="*60)
  total_time = print_inference_time(start_time, end_time, device)
  print(f"Mem alloc for inference: {memuse_post_onestep} KiB \t Total including init: {memuse_total:.3f}KiB")
  print(f"Accuracy on {leave_out}: {acc}% | MAE: {mae:.5f} | RMSE: {rmse:.5f}")
  print(f"RUL Actual: {RUL_true} | RUL Predicted: {RUL_pred} | RUL Error: {RUL_error}\n{'-'*64}")

  # Plotting
  plt.subplot(1,4,idx+1)
  plt.plot(y_test[leave_out].cpu(),'k--',label="Ground Truth")
  plt.plot(pred.cpu(),'r-',label="Predictions")
  plt.title(f"One-step ahead for Battery {leave_out}")
  plt.legend()
  plt.xlabel('Number of Discharge Cycles')
  plt.ylabel('Capacity (in Ah)')
  plt.grid()

  OSP_ELM_CALCE[leave_out] = {
      "model_name": leave_out,
      "mem_usage": memuse_total,
      "exec_time": total_time,
      "acc": acc,
      "mae": mae,
      "rmse": rmse,
      "rul_error": int(RUL_error),
      "RUL_relative_error": float(RUL_relative_error)
  }

plt.savefig('One-step_ELM_CALCE.pdf')

import pandas as pd
# Convert to PD DataFrame
OSP_results = pd.DataFrame([OSP_ELM_CALCE['CS2_35'],
                            OSP_ELM_CALCE['CS2_36'],
                            OSP_ELM_CALCE['CS2_37'],
                            OSP_ELM_CALCE['CS2_38']
                            ])
# Saving results
OSP_results.to_pickle("OSP_ELM_CALCE.pkl")

"""### Multi-Step Ahead"""

def plot_predictions(train_cap, train_cyc, label_cap, label_cyc, predictions, title):
  plt.title(title)
  plt.plot(train_cyc, train_cap, 'k-', label='Training data')
  plt.plot(label_cyc, label_cap, 'k:', label='Ground Truth')
  plt.plot(label_cyc, predictions, 'b-', label='Prediction')
  plt.legend()
  plt.xlabel('Number of Discharge Cycles')
  plt.ylabel('Capacity (in Ah)')
  plt.grid()

predictions = {}
plt.figure(figsize=(40,7))
plt.suptitle(f'ELM (CALCE) Multi-Step Ahead', fontsize=16, weight='bold')

MSP_ELM_CALCE = {}

for leave_out, idx in zip(Battery_list, range(len(Battery_list))):
  # access dictionary contents
  eval_cap, eval_cyc = test_sequence[leave_out][leave_out]
  test_cap, test_cyc = test_labels[leave_out][leave_out]

  # convert lists to tensors
  eval_cap, eval_cyc = eval_cap, eval_cyc
  test_cap, test_cyc = np.array(test_cap), np.array(test_cyc)

  # create point list which contains predictions
  preds = []
  # sequence which contains prediction inputs (last window_size entries of array)
  seq = eval_cap[-window_size:].tolist()

  # Begin timer and capture memory stats before inference
  start_time = timer()
  tracemalloc.start()

  for j in range(len(test_cap)):
    pred = model[leave_out](torch.tensor(seq, dtype=torch.float32, device=device))
    seq = seq[1:]
    seq.append(np.float64(pred))
    preds.append(np.float64(pred))

  # End timer and capture memory stats after inference
  end_time = timer()
  memsnap_post_multistep = tracemalloc.take_snapshot()
  tracemalloc.stop()

  # copy preds to dictionary
  preds = np.array(preds)
  predictions[leave_out] = preds

  # plot predictions
  plt.subplot(1, 4, idx+1)
  plot_predictions(train_cap = eval_cap,
                   train_cyc = eval_cyc,
                   label_cap = test_cap,
                   label_cyc = test_cyc,
                   predictions = preds,
                   title =  f"Prediction for Battery {leave_out}")
  
  # Compute memory usage
  memuse_post_multistep = memory_stats(memsnap_post_multistep, print_mem=False)
  memuse_total = memuse_post_multistep + memuse_end_setup

  # Computing metrics
  error = np.abs(preds - test_cap)/test_cap
  acc = np.ones_like(error) - error
  acc = 100*np.sum(acc)/len(test_cap)
  mae = mean_absolute_error(test_cap,preds)
  rmse = sqrt(mean_squared_error(test_cap,preds))

  # Computing RUL Error
  Threshold = 0.7 * Rated_Capacity
  idx_true = (test_cap<Threshold).nonzero()        # search idx less than threshold
  RUL_true = idx_true[0][0]                        # first entry is true RUL

  idx_preds = (preds<Threshold).nonzero()          # search idx less than threshold
  RUL_preds = idx_preds[0][0]                         # first entry is pred RUL
  RUL_error = RUL_true - RUL_preds                 # if positive value, early RUL; 
                                                   # negative value, late RUL
  RUL_relative_error = RUL_error / RUL_true
  rul_preds_list[leave_out] = RUL_preds

  # Printing metrics
  print(f"Extreme Learning Machine (window_size={window_size}, hidden_dim={hidden_dim})\nMulti-step Ahead Prediction for Battery {leave_out}")
  print("="*60)

  total_time = print_inference_time(start_time, end_time, device)
  print(f"Memory alloc for inference: {memuse_post_multistep:.3f} KiB \t Including init: {memuse_total:.3f} KiB")
  print(f"Accuracy: {acc:.4f}% | MAE: {mae:.4f} | RMSE: {rmse:.4f}")
  print(f"RUL True: {RUL_true} | RUL Predicted: {RUL_preds} | RUL Error: {RUL_error}\n{'-'*60}")

  MSP_ELM_CALCE[leave_out] = {
      "model_name": leave_out,
      "mem_usage": memuse_total,
      "exec_time": total_time,
      "acc": acc,
      "mae": mae,
      "rmse": rmse,
      "rul_error": int(RUL_error),
      "RUL_relative_error": float(RUL_relative_error)
  }

plt.savefig('Multi-step_ELM_CALCE.pdf')

# Convert to PD DataFrame
MSP_results = pd.DataFrame([MSP_ELM_CALCE['CS2_35'],
                            MSP_ELM_CALCE['CS2_36'],
                            MSP_ELM_CALCE['CS2_37'],
                            MSP_ELM_CALCE['CS2_38']
                            ])
# Saving results
MSP_results.to_pickle("MSP_ELM_CALCE.pkl")

# Print to 16x2 LCD
if args.print:
    # LCD Stuff
    from Adafruit_CharLCD import Adafruit_CharLCD
    from time import sleep

    # Initialize LCD and specify pins
    lcd = Adafruit_CharLCD(rs=26, en=19,
                           d4=13, d5=6, d6=5, d7=21,
                           cols=16, lines=2)
    # Clear the LCD
    lcd.clear()
    for leave_out in Battery_list:
        # Display message
        lcd.clear()
        lcd.message(f'Cycles left for\n{leave_out}: {rul_preds_list[leave_out]}')
        sleep(5)